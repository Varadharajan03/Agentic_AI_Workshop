{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit langchain langchain-community langchain-google-genai google-generativeai chromadb PyMuPDF python-docx fpdf pyngrok tavily-python\n",
        "!ngrok config add-authtoken 2yZx6j4QmLr9F8kIJze2bwTBJi8_6oBu1UBC5dmaNf8vvdJ6F"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oNt4TvZdbPJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py with Full Agent Implementation (LangGraph Style) to Score 10/10\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import fitz\n",
        "import streamlit as st\n",
        "from docx import Document as DocxDocument\n",
        "from fpdf import FPDF\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "\n",
        "# === API Keys ===\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDeLmTuK6pAQ5TTP7mYNM7fpXazmXJUTAs\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "\n",
        "# === Helper Functions ===\n",
        "def extract_text_from_file(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        doc = fitz.open(file_path)\n",
        "        return \"\\n\".join([page.get_text() for page in doc])\n",
        "    elif ext == \".docx\":\n",
        "        doc = DocxDocument(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "def generate_pdf(text):\n",
        "    import re\n",
        "    def remove_emojis(text):\n",
        "        return re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    for line in text.split('\\n'):\n",
        "        cleaned_line = remove_emojis(line)\n",
        "        pdf.multi_cell(0, 10, cleaned_line)\n",
        "    pdf_path = os.path.join(tempfile.gettempdir(), \"intent_report.pdf\")\n",
        "    pdf.output(pdf_path)\n",
        "    return pdf_path\n",
        "\n",
        "# === LangChain Setup ===\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "def setup_agents(text, domain_filter, exp_level):\n",
        "    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = [Document(page_content=chunk) for chunk in splitter.split_text(text)]\n",
        "    embedder = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    vectordb = Chroma.from_documents(docs, embedder, persist_directory=\"./intent_vector_db\")\n",
        "    retriever = vectordb.as_retriever()\n",
        "\n",
        "    def build_chain(template):\n",
        "        return RetrievalQA.from_chain_type(\n",
        "            llm=llm, retriever=retriever, return_source_documents=False,\n",
        "            chain_type_kwargs={\"prompt\": PromptTemplate(input_variables=[\"context\"], template=template)}\n",
        "        )\n",
        "\n",
        "    # Define each agent prompt\n",
        "    intent_prompt = \"\"\"\n",
        "As a career analysis assistant, extract key user intent from the text below.\n",
        "Return a structured response with:\n",
        "- **Interests**\n",
        "- **Motivation**\n",
        "- **Core Skills**\n",
        "Text:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "    pattern_prompt = \"\"\"\n",
        "You're a career analyst. Review the following content and compare with known success patterns.\n",
        "Return:\n",
        "- Career paths that align with user background\n",
        "- Gaps in the SOP or profile\n",
        "- Suggestions for improvement\n",
        "Content:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "    role_prompt = f\"\"\"\n",
        "Based on the user's interests, skills, and motivation, suggest 2-3 job roles in the domain: {domain_filter} and experience level: {exp_level}.\n",
        "For each role, return:\n",
        "- Role Title\n",
        "- Reason for recommendation\n",
        "- Rating out of 100\n",
        "Text:\n",
        "{{context}}\n",
        "\"\"\"\n",
        "\n",
        "    misalign_prompt = \"\"\"\n",
        "Given the user's profile and roles, identify any roles that do not align with their interests or skills.\n",
        "Return:\n",
        "- Misaligned roles (if any)\n",
        "- Suggestions for reskilling or alignment\n",
        "Text:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "    resume_prompt = \"\"\"\n",
        "Based on the user's background and the suggested roles, provide 3 tailored suggestions to improve their resume or portfolio.\n",
        "Text:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "    # Agents\n",
        "    agents = [\n",
        "        Tool(name=\"Intent Extractor\", func=lambda x: build_chain(intent_prompt).invoke(x)['result'], description=\"Extracts user intent\"),\n",
        "        Tool(name=\"Pattern Analyzer\", func=lambda x: build_chain(pattern_prompt).invoke(x)['result'], description=\"Analyzes user patterns\"),\n",
        "        Tool(name=\"Role Matcher\", func=lambda x: build_chain(role_prompt).invoke(x)['result'], description=\"Recommends job roles\"),\n",
        "        Tool(name=\"Misalignment Flagger\", func=lambda x: build_chain(misalign_prompt).invoke(x)['result'], description=\"Detects misalignments\"),\n",
        "        Tool(name=\"Resume Tailor\", func=lambda x: build_chain(resume_prompt).invoke(x)['result'], description=\"Improves resume\")\n",
        "    ]\n",
        "\n",
        "    agent = initialize_agent(agents, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "    return agent\n",
        "\n",
        "# === Streamlit App ===\n",
        "st.set_page_config(page_title=\"🎯 Intent-Based Job Role Recommender\")\n",
        "st.title(\"🎯 Intent-Based Job Role Recommender\")\n",
        "st.markdown(\"Upload SOP or GitHub Summary (PDF/DOCX). System will analyze and suggest roles.\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"📄 Upload your file\", type=[\"pdf\", \"docx\"])\n",
        "domain_filter = st.selectbox(\"🌐 Select Target Job Domain\", [\"Any\", \"Frontend\", \"Backend\", \"UX\", \"Data Science\", \"Cloud\"])\n",
        "exp_level = st.selectbox(\"📈 Select Experience Level\", [\"Any\", \"Beginner\", \"Intermediate\", \"Advanced\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:\n",
        "        tmp.write(uploaded_file.read())\n",
        "        temp_path = tmp.name\n",
        "\n",
        "    st.info(\"🔍 Analyzing your file...\")\n",
        "    try:\n",
        "        text = extract_text_from_file(temp_path)\n",
        "        agent = setup_agents(text, domain_filter, exp_level)\n",
        "\n",
        "        query = \"\"\"Extract intent, analyze patterns, suggest roles, check misalignments, and recommend resume improvements based on the user's uploaded content.\"\"\"\n",
        "        result_text = agent.run(query)\n",
        "\n",
        "        st.success(\"✅ Recommendation generated!\")\n",
        "        st.markdown(result_text, unsafe_allow_html=True)\n",
        "\n",
        "        pdf_path = generate_pdf(result_text)\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            st.download_button(\"📄 Download PDF Report\", data=f, file_name=\"intent_recommendation.pdf\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ Error: {e}\")\n"
      ],
      "metadata": {
        "id": "chXQmv4Bbrub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n",
        "!pkill -f streamlit\n",
        "!streamlit run app.py &>/content/log.txt &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "url = ngrok.connect(8501)\n",
        "print(\"🔗 Open your Streamlit app:\", url)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UzpHcj4mhxlN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}